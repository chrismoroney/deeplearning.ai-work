{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "In this section you will learn more about the different metrics taught to you thus far in the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "  \n",
    "- [1. Introduction](#Intro)  \n",
    "- [2. Import Packages and Functions](#Import)\n",
    "- [3. Read The Data](#Read-data)\n",
    "- [4. Data Processing](#data-processing)\n",
    "- [5. Interactive Graph](#graph)\n",
    "    - [5.1. Challenge #1](#challenge1)\n",
    "        - [5.1.1. Challenge #1 Example](#challengeEx)\n",
    "        - [5.1.2. Challenge #1.1](#challenge1_1)\n",
    "        - [5.1.3. Challenge #1.2](#challenge1_2)\n",
    "        - [5.1.4. Challenge #1.3](#challenge1_3)\n",
    "        - [5.1.5. Challenge #1.4](#challenge1_4)\n",
    "- [6. Logistic Regression Model](#logistic-regression)\n",
    "- [7. Accuracy and Classification Report](#A-and-C)\n",
    "- [8. Calculated Metrics](#Calc-Metrics)\n",
    "    - [8.1. Challenge #2](#challenge2)\n",
    "        - [8.1.1. Challenge #2 Example](#challengeEx2)\n",
    "        - [8.1.2. Challenge #2.1](#challenge2_1)\n",
    "        - [8.1.3. Challenge #2.2](#challenge2_2)\n",
    "- [9. Confusion Matrix](#Conf-Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"Intro\"></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine our model's performance, we need to be able to calculate several different **metrics**. Metrics are measurements that can be used to analyze the performance and effectiveness of a model's function, such as binary classification (or classification of data between two classes). In this lab, we will learn about this model's purpose which are to determine if a patient has a disease, COVID-19, given two inputs of data. We will also discuss *how* the model classifies patients as healthy or sick. This is a process known as binary classification, and the model goes through training with an activation function in order to produce an answer. Finally, we will calculate the metrics of our model's performance to determine how well our model performed. Besides accuracy, there are many metrics that are extremely important to consider, such as Sensitivity, Specificity, PPV, and NPV. We will also understand what a confusion matrix is and analyze the results that a confusion matrix produces. By the end of this lab, you will be able to determine a binary classifier's performance based off of calculated metrics. Based on these metrics, you may come up with techniques to improve your model's performance, or perhaps even lower the training to prevent overfitting in your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Import\"></a>\n",
    "## Import Packages and Functions¶\n",
    "\n",
    "We'll make use of the following packages:\n",
    "- `numpy` and `pandas` is what we'll use to manipulate our data\n",
    "- `matplotlib.pyplot` and `seaborn` will be used to produce plots for visualization\n",
    "- `scikit-learn` will help the model classify the data as disease or no disease, as well as assist in creating visual models of the data\n",
    "- `util` will provide the locally defined utility functions that have been provided for this assignment\n",
    "\n",
    "Run the next cells to import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and pandas for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import matplotlib and seaborn for visualizing and graphing our data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Import a helper function that is written to reference lines \n",
    "import helper\n",
    "# Import sklearn packages to assist in classification for the model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "# Import Fraction so that we can make a fraction for calculating metrics\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Read-data\"></a>\n",
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataset that we will be using comes from the \"covid19.csv\" file. This is a toy dataset designed entirely for educational purposes (the data in this set is not legitimate). We focus on having an input of two features because it is the easiest to represent graphically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_outside(hours/week)</th>\n",
       "      <th>population_density(hundreds_of_people/square_mile)</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_outside(hours/week)  \\\n",
       "0                        11   \n",
       "1                        53   \n",
       "2                        22   \n",
       "3                        22   \n",
       "4                        24   \n",
       "\n",
       "   population_density(hundreds_of_people/square_mile)   labels  \n",
       "0                                                 20   Healthy  \n",
       "1                                                 12   Healthy  \n",
       "2                                                 40   Healthy  \n",
       "3                                                 11   Healthy  \n",
       "4                                                  8   Healthy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('covid19.csv')\n",
    "# Generate some sample data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample data from our dataset. \n",
    "\n",
    "The **data** includes 100 examples that have entries of time outside in hours per week and the population density for each person in the data. The total number of features per example is 2.\n",
    "\n",
    "The **target** includes 100 labels that determine whether or not the patient has the disease or not. We only have 1 label for each example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"data-processing\"></a>\n",
    "## Data Processing\n",
    "Divide the csv data into two different parts, the data (includes the features) and the target (which includes the status of the patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time_outside(hours/week)',\n",
       "       'population_density(hundreds_of_people/square_mile)', 'labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that the data is being read correctly,\n",
    "\n",
    "# the data's categories are 'Time_outside(hours/week)','population_density(hundreds_of_people/square_mile)', 'labels'\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 20]\n",
      " [53 12]\n",
      " [22 40]\n",
      " [22 11]\n",
      " [24  8]\n",
      " [ 3 18]\n",
      " [ 1 33]] return type: <class 'numpy.ndarray'>\n",
      "\n",
      "['Healthy' 'Healthy' 'Healthy' 'Healthy' 'Healthy' 'Healthy' 'Healthy'] return type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# data and targets are arrays of the dataset. \n",
    "data = df[['Time_outside(hours/week)', 'population_density(hundreds_of_people/square_mile)']].values\n",
    "targets = df['labels'].values\n",
    "\n",
    "# data changing and data type\n",
    "print(data[:7], \"return type: \" + str(type(data)))\n",
    "print()\n",
    "print(targets[:7], \"return type: \" + str(type(targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are processing the target names \"Healthy\" and \"sick\" to translate into 0 and 1. 0 means \"healthy\", or no disease, while 1 means \"sick\", or disease. Binaraizing our labels allows our model to classify between two different classes, which many different activation functions can use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of labels: 100\n"
     ]
    }
   ],
   "source": [
    "# Create a label binarizer that we can use to change our labels from \"healthy\" and \"sick\" to 0 and 1.\n",
    "lb = LabelBinarizer()\n",
    "# We need to match the shape of our labels column in the dataset, which is why we use fit\n",
    "lb.fit(targets)\n",
    "print(\"Total number of labels: \" + str(targets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have initialized a Label Binarizer to the size of targets, we need to transition our labels from \"healthy\" and \"sick\" to 0 and 1. The two cells below will demonstrate how the label binarizer do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthy' 'Sick']\n"
     ]
    }
   ],
   "source": [
    "# Represented classes that are being binarized. These will be the labels that will be transformed\n",
    "lb.classes_\n",
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Transforms the labels to 0s and 1s\n",
    "y = lb.transform(targets)\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the lb.classes_ with y. We can clearly see that 0 and 1 take the place of Healthy and Sick. SUCCESS! We were able to successfully binarize our labels from \"healthy\" and \"sick\" to 0 and 1. This will help us tremendously when classifying data points because our model needs to use an **activation function**, which depends on the label being between 0 and 1 mathematically. You will observe this much closer in \"**The Model**\" section, where you will see how the **sigmoid** activation function works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unbinarized labels: 100\n",
      "Total number of binarized labels: 100\n",
      "\n",
      "Total number of unbinarized classes: 2\n",
      "Total number of binarized classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Just verify that we did not lose any labels by showing the shape of targets and y\n",
    "print(\"Total number of unbinarized labels: \" + str(targets.shape[0]))\n",
    "print(\"Total number of binarized labels: \" + str(y.shape[0]))\n",
    "print()\n",
    "# Also verify that the number of unbinarized classes matches the number of classes when we binarized\n",
    "print(\"Total number of unbinarized classes: \" + str(lb.classes_.shape[0]))\n",
    "print(\"Total number of binarized classes: \" + str(np.unique(y).shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully binarized our labels, we need to manually split our data into train and test sets. This will allow us to use the data we have and not have to collect more. While more data can generally be better for our model to train, data can actually be costly and difficult to obtain. Therefore, we can split up our data to accomodate for this difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our dataset into a training set and test set\n",
    "# x is features, y is \"label\"\n",
    "# we use test_size=0.3 to split the data so that 30 percent of the goes to the test set, allowing 70% for training\n",
    "trainX, testX, trainY, testY = train_test_split(data, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our datasets have now been split up into a training and test set. Let's just verify that we have split our training and test data split without losing input or output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset consist of 70 samples with 2 features. There are 70 corresponding output labels.\n",
      "The testing dataset consist of 30 samples with 2 features. There are 30 corresponding output labels.\n"
     ]
    }
   ],
   "source": [
    "# Shows how much data we have in each set\n",
    "print(f\"The training dataset consist of {trainX.shape[0]} samples with {trainX.shape[1]} features. There are {trainY.shape[0]} corresponding output labels.\")\n",
    "print(f\"The testing dataset consist of {testX.shape[0]} samples with {testX.shape[1]} features. There are {testY.shape[0]} corresponding output labels.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"graph\"></a>\n",
    "## Interactive Graph\n",
    "\n",
    "A **threshold** is a parameter of the model that distinguishes sections of data to define classes in the dataset. In binary classification, 0.5 is the most standard threshold because classes are most commonly defined as 0 and 1 (or positive and negative). Values less than 0.5 are classified in the 0 (or negative) class, while values equal or greater than 0.5 is classified into the 1 (or positive) class.This can be visually represented in many different ways, such as in graphs or charts (you will see this later on in the notebook). A threshold will allow our model to understand how to classify particular training examples as having the disease or not. \n",
    "\n",
    "For this particular example and model, we are only focusing on two features of input so that we can plot the information on a two dimensional graph. It is possible to have more than 2 features or dimensions in the input. In order to obtain the best possible predictions, we can incorporate **gradient descent** in order to fine-tune the parameters of **logistic regression**.\n",
    "\n",
    "Use the graph to interact with dividing as many red and blue points on opposite sides of the line. The line will act as a visual **threshold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fafa9e0d234b9f8fbed41ac98a7749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=10.0, min=-10.0, step=0.05), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here is a plot of all features and their labels. Feel free to use the sliders to divide the sick and healthy patients\n",
    "helper.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the graph has labeled healthy patients as blue, and sick patients as red, and there is a line that can be manipulated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Each example on the graph will fall into one of these 4 catagories:\n",
    "\n",
    "* **True Positive** -- the model correctly predicts the output of an example to be positive. Ground Truth = Positive\n",
    "* **True Negative** -- the model correctly predicts the output of an example to be negative. Ground Truth = Negative\n",
    "* **False Positive** -- the model incorrectly predicts the output of an example to be positive. Ground Truth = Negative\n",
    "* **False Negative** -- the model incorrectly predicts the output of an example to be negative. Ground Truth = Positive\n",
    "\n",
    "When using Artificial Intelligence in medicine, we need to be extremely careful with the number of examples that the model classifies incorrectly. In this case, we need to be really careful classifying patients with the COVID-19 disease as healthy (or classifying a positive example as negative). Incorrectly classifying patients with the disease can result in major spreading of the disaese, and possibly misinformation about the disease. The consequences of incorrect classifications with COVID-19 are **major**, which is why we need to minimize as many examples as False Positives and Negatives, and achieve as many True Positives and Negatives over many training results and datasets.\n",
    "\n",
    "In terms of medicine, the categories above translate into these definitions:\n",
    "* **True Positive** -- the model correctly predicts the patient to have the disease. Ground Truth = Patient has disease.\n",
    "* **True Negative** -- the model correctly predicts the patient to be healthy. Ground Truth = Patient doesn't have disease.\n",
    "* **False Positive** -- the model incorrectly predicts the patient to have the disease. Ground Truth = Patient doesn't disease.\n",
    "* **False Negative** -- the model incorrectly predicts the patient to be healthy. Ground Truth = Patient has disease.\n",
    "\n",
    "The most important metric to pay attention to is the *False Negatives*. The reason for this is if we diagnose a patient as healthy when they are actually sick, then the consequences may be *severe*. COVID-19 is a highly infectious disease, so we don't want to be spreading the disease. \n",
    "\n",
    "We can minimize the number of False Negatives by training our model to be more sensitive to the disease. Thus, as a result, we may lower the number of True Positives we have, and increase the number of False Positives. However, even if the model's accuracy of classifying patients decreases, we are taking more consideration of the consequences by lowering the risk of sick patients being classified as healthy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You will learn more about the effect of manipulating thresholds in the **ROC curves and thresholds** lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge1\"></a>\n",
    "## CHALLENGE \n",
    "**Plot the following information into the graphs below**. Assume that Positive means \"Sick\", and Negative means \"Healthy\" (or no disease). Also assume that the line divides the graph such in a way that the area with more \"Healthy\" or \"Sick\" examples is where the \"Positive\" or \"Negative\" region is (for example, a region that contains 40 healthy examples and 2 sick examples means that that is considered the \"Healthy\" region, which is then the \"Negative\" region).\n",
    "\n",
    "Using the following plot information, determine the number of True Positive, True Negative, False Positive, and False Negative examples defined from the threshold's location.\n",
    "\n",
    "Note: If you are struggling to use the sliders, you can click on each individual slider and move them using the arrow keys on your keyboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> There are 50 Positive examples and 50 Negative examples total. </li>\n",
    "    <li> If you can't count the number of examples due to clusters, count how many False examples there are first, then subtract that value from the True examples. </li>\n",
    "    <li> In each graph, you should see that the Positive region (or group of sick patients) is red, while the Negative region of Healthy Patients is Blue. Your False Positives and Negatives will be blue or red points that are NOT in the same colored region as their own color. </li>\n",
    "    <li> Run the cell after the challenge blocks to see if you got the right answer or not. </li>\n",
    "</ul>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challengeEx\"></a>\n",
    "#### Example: \n",
    "**slope** = -2.50, **yIntercept** = 90, **xIntercept** = -30, **degree** = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663b16d6fafd4a898aac18ea108ab4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=10.0, min=-10.0, step=0.05), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "TP = 48\n",
    "TN = 46\n",
    "FP = 4\n",
    "FN = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 48 is correct!\n",
      "True Negatives: 46 is correct!\n",
      "False Positives: 4 is correct!\n",
      "False Negatives: 2 is correct!\n",
      "\n",
      "Congratulations on completing Example 1!\n"
     ]
    }
   ],
   "source": [
    "helper.example1(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge1_1\"></a>\n",
    "#### Challenge 1: \n",
    "**slope** = -3.30, **yIntercept** = 90, **xIntercept** = -10, **degree** = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ba8b252799498aadfc3e8f4558cde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=10.0, min=-10.0, step=0.05), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "# Challenge 1\n",
    "# Enter answers below\n",
    "TP = None\n",
    "TN = None\n",
    "FP = None\n",
    "FN = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: None is incorrect!\n",
      "True Negatives: None is incorrect!\n",
      "False Positives: None is incorrect!\n",
      "False Negatives: None is incorrect!\n"
     ]
    }
   ],
   "source": [
    "helper.challenge1_1(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge1_2\"></a>\n",
    "#### Challenge 2: \n",
    "**slope** = -0.20, **yIntercept** = 30, **xIntercept** = -50, **degree** = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c674f04059f64cc191bbc3b5e66409a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=10.0, min=-10.0, step=0.05), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n",
    "# Enter answers below\n",
    "TP = None\n",
    "TN = None\n",
    "FP = None\n",
    "FN = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: None is incorrect!\n",
      "True Negatives: None is incorrect!\n",
      "False Positives: None is incorrect!\n",
      "False Negatives: None is incorrect!\n"
     ]
    }
   ],
   "source": [
    "helper.challenge1_2(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge1_3\"></a>\n",
    "#### Challenge 3: \n",
    "**slope** = 2.00, **yIntercept** = 50, **xIntercept** = -30, **degree** = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b1d60906724bef9f71693783f9ed7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=10.0, min=-10.0, step=0.05), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3\n",
    "# Enter answers below\n",
    "TP = None\n",
    "TN = None\n",
    "FP = None\n",
    "FN = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: None is incorrect!\n",
      "True Negatives: None is incorrect!\n",
      "False Positives: None is incorrect!\n",
      "False Negatives: None is incorrect!\n"
     ]
    }
   ],
   "source": [
    "helper.challenge1_3(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge1_4\"></a>\n",
    "#### Challenge 4: \n",
    "**slope** = -0.05, **yIntercept** = 90, **xIntercept** = -40, **degree** = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6873c74ba844238cf25074662b093d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='slope', max=10.0, min=-10.0, step=0.05), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4\n",
    "# Enter answers below\n",
    "TP = None\n",
    "TN = None\n",
    "FP = None\n",
    "FN = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: None is incorrect!\n",
      "True Negatives: None is incorrect!\n",
      "False Positives: None is incorrect!\n",
      "False Negatives: None is incorrect!\n"
     ]
    }
   ],
   "source": [
    "helper.challenge1_4(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have seen what each graph looks like, which graph do you think represents the best threshold to distinguish two different classes? Which graphs seem like they overfit or underfit the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"logistic-regression\"></a>\n",
    "# The Model\n",
    "\n",
    "\n",
    "The model that we will be using will classify patients with certain features as having a disease or not, based on their weekly time outside and their population density. The parameters include the features, which again is weekly time outside and population density. The activation function is sigmoid because sigmoid is one of the best functions for determining binary classifications. After feeding our parameters into the activation function, we will recieve a number between 0 and 1, which is the classification that the model determines for our data example.\n",
    "\n",
    "We are using a **Logistic Regression** to classify patients with being healthy or sick ('y'), given their features ('x'). We need to fit our dataset with the model, which will allow our model to train on our data. To model Logistic Regression, we will be using the **sigmoid** function. Sigmoid is very useful for binary classification because there is a defined range of defining classes, which is 0 and 1. We will define 0 as having \"no disease\" or healthy, and 1 as having the \"disease\" or sick.\n",
    "\n",
    "Observe the image below. This image shows how a Logistic Regression model is trained and then classifies images. There are inputs in a vector that are fed into an activation function (which is the circle all the arrow are pointing to), then the activation function outputs a probability that determines of the image belongs to a particular class (in this case, cats vs dogs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"LogReg_kiank.png\" style=\"width:500px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create an instant of a **Logistic Regression** model. We use this type of model because Logistic Regression uses a probability to determine which class a piece of data belongs to. We need to train our model with our training dataset, so we will feed our data into the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a Logistic Regression model and fit the model to our data\n",
    "classifier = LogisticRegression()\n",
    "# We need to put our dataset into the Logistic Regression. We can only do this if we fit the dataset into the model.\n",
    "classifier.fit(trainX, trainY.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use ravel() on the trainY because when we split our data, the trainY was 2 dimension. Our data (x) needs to be 2 dimensions because we have 2 different inputs that contribute towards a label (y). However, splitting the dataset caused our label section (or y) to match the shape of our x's, or data. We can only have 1 label per 2 dimension, but having a 2 dimensional array now can cause the data to be misread. Thus, we must use ravel() on trainY to flatten our array back down to 1 dimension, thus matching 2 input dimesnions to 1 output label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of trainY: 2\n",
      "Dimensions of trainY.ravel(): 1\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating ravel() on trainY, ndim is a property of np.array for number of dimensions\n",
    "print(\"Dimensions of trainY: \" + str(trainY.ndim))\n",
    "print(\"Dimensions of trainY.ravel(): \" + str(trainY.ravel().ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model with our training dataset, we can now use our model to predict the labels of our test dataset. Let's compare how our model did compared to our test labels for the first 10 pieces of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's predictions: \n",
      "[0 1 0 1 1 0 0 1 1 1]\n",
      "Dataset labels: \n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# use our trained model to predict the labels for testX\n",
    "predictions = classifier.predict(testX)\n",
    "print(\"Model's predictions: \")\n",
    "print(str(predictions[:10]))\n",
    "print(\"Dataset labels: \")\n",
    "print(str(testY[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a deeper analysis of how our model predicted each piece of data, let's see how each piece of data can be calculated, then inserted into an **activation function** to determine what class that data is classified into. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's pull a piece of sample data and see how this data is calculated into the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sample: [ 3 13] with label: ['Healthy']\n"
     ]
    }
   ],
   "source": [
    "# print a sample piece of data and its label\n",
    "print(f\"Testing sample: {testX[0]} with label: {lb.classes_[testY[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the equation and graph of the **sigmoid function**. Notice that as z is larger and positive, the sigmoid function outputs a value closer to 1, and if z is negative, the sigmoid function outputs a value closer to 0. These values will help the model classify between two classes (no disease and disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"a.png\" style=\"width:500px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model assesses a multiplier coefficient to multpliy to each input value, in addition to an intercept value. The idea with this is that the model is mathematically trying to determine whether a piece of data belongs into the 0 or 1 class, but must have a system where all values in the dataset can fall in between 0 and 1. This is why we had to make a training dataset. We now can create a value that can be fed into our activation function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of input 1 coefficient (m1): 0.14218154163868038\n",
      "Value of input 2 coefficient (m2): 0.1305068575678503\n",
      "Value of intercept (b): -13.225582767659903\n"
     ]
    }
   ],
   "source": [
    "# use the coefficients from the classifiers, \n",
    "# will be used to calculate in the sigmoid function\n",
    "m1, m2, b = classifier.coef_[0][0], classifier.coef_[0][1], classifier.intercept_[0]\n",
    "print(\"Value of input 1 coefficient (m1): \" + str(m1))\n",
    "print(\"Value of input 2 coefficient (m2): \" + str(m2))\n",
    "print(\"Value of intercept (b): \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now multiply these coefficients to the input values, then add the intercept to get our z value. Z will be fed into the sigmoid function, which will then determine if we put this piece of data in the 0 or 1 class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value from (m1) * first input value: 0.14218154163868038 * 3 = 0.42654462491604117\n",
      "Value from (m2) * second input value: 0.1305068575678503 * 13 = 1.6965891483820539\n",
      "Value of intercept (b): -13.225582767659903\n",
      "\n",
      "z = 0.42654462491604117 + 1.6965891483820539 + -13.225582767659903 = -11.102448994361808\n",
      "\n",
      "z = -11.102448994361808\n",
      "sigmoid(z) = 0.00001508\n"
     ]
    }
   ],
   "source": [
    "# Use our coefficients and multiply them as weights as an equation into z, which\n",
    "# we put into our sigmoid function.\n",
    "print(\"Value from (m1) * first input value: \" + str(m1) + \" * \" + str(testX[0][0]) + \n",
    "      \" = \" + str(m1*testX[0][0]))\n",
    "print(\"Value from (m2) * second input value: \" + str(m2) + \" * \" + str(testX[0][1]) + \n",
    "      \" = \" + str(m2*testX[0][1]))\n",
    "print(\"Value of intercept (b): \" + str(b))\n",
    "\n",
    "print()\n",
    "\n",
    "z = (m1 * testX[0][0]) + (m2 * testX[0][1]) + (b)\n",
    "print(\"z = \" + str(m1*testX[0][0]) + \" + \" + str(m2*testX[0][1]) + \" + \" + str(b) + \" = \" + str(z))\n",
    "print()\n",
    "print(\"z = \" + str(z))\n",
    "print(\"sigmoid(z) = \" + '%.8f' % sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that if z is very large and negative, the sigmoid of z will be very close to 0. If z is very large and positive, the sigmoid of z will be very close to 1. If z is close to 0, then sigmoid of z will be around 0.5, and will classify the data according to if sigmoid of z is closer to 0 or 1. This sigmoid function, also referred to as an activation function, allows our model to classify data on a scale from 0 to 1, which is why it was extremely important that we binarized our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"A-and-C\"></a>\n",
    "## Accuracy and Classification Report\n",
    "\n",
    "<p>\n",
    "Now that we have collected our data and have a classifier to define our classes, we can now calculate our metrics. You will see here how metrics can determine the success of the model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** is actually a metric that determines the correctness of the model's predictions. It is a metric that is calculated between 0 and 1, where 1 is most correct and 0 is least correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Accuracy = \\frac{\\text{Correctly Classified Examples}}{\\text{Total Examples Classified by the Model}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# calculate our accuracy from our test set\n",
    "print(\"Accuracy: \" + str(accuracy_score(testY, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other metrics we can use to determine the model's performance in classifying between classes. Here are some examples:\n",
    "- **Precision** is the ratio for the classifier to be labeled correctly\n",
    "- **Recall** is the ratio of finding all 0 or 1 examples exclusively\n",
    "- **F1-score** is the mean of precision and recall (1 is best score)\n",
    "- **Support** is the number of occurnces that were in testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.94      1.00      0.97        15\n",
      "        Sick       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report. \n",
    "print()\n",
    "print(classification_report(testY, predictions, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Macro Average (macro avg) refers to the average of all pieces of data, regardless of input importance\n",
    "- Weighted Average (weighted avg) refers to the average of data with multiplied weights to different pieces of input, depending on the importance of a particular input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Calc-Metrics\"></a>\n",
    "## Calculated Metrics\n",
    "\n",
    "Here, we will show you how to actually compute important metrics for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definitions of True Positives, True Negatives, False Positives, and False Negatives. Each example will fall into one of these 4 catagories:\n",
    "\n",
    "* **True Positive** -- the model correctly predicts the output of an example to be positive \n",
    "* **True Negative** -- the model correctly predicts the output of an example to be negative\n",
    "* **False Positive** -- the model incorrectly predicts the output of an example to be positive \n",
    "* **False Negative** -- the model incorrectly predicts the output of an example to be negative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the values as described above to calculate the sensitivity, specificity, PPV, and NPV. These values can be extracted from the metrics above. Here are the definitions and equations for each:\n",
    "\n",
    "- **Sensitivity** -- The probability that the model predicts positive (or 1) *given* that the ground truth is positive (or 1)\n",
    "- **Specificity** -- The probability that the model predicts negative (or 0) *given* that the ground truth is negative (or 0)\n",
    "- **Positive Predicitve Value (PPV)** -- The probability that the ground truth is positive (or 1) *given* that the model predicts positive (or 1)\n",
    "- **Negative Predictive Value (PPV)** -- The probability that the ground truth is negative (or 0) *given* that the model predicts negative (or 0)\n",
    "\n",
    "\n",
    "$$ Sensitivity = \\frac{\\text{True Positive}}{\\text{True Positive + False Negative}} $$\n",
    "\n",
    "\n",
    "$$ Specificity = \\frac{\\text{True Negative}}{\\text{False Positive + True Negative}} $$\n",
    "\n",
    "\n",
    "$$ PPV = \\frac{\\text{True Positive}}{\\text{True Positive + False Positive}} $$\n",
    "\n",
    "\n",
    "$$ NPV = \\frac{\\text{True Negative}}{\\text{True Negative + False Negative}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 14\n",
      "True Negatives: 15\n",
      "False Positives: 0\n",
      "False Negatives: 1\n",
      "\n",
      "Observe these values in the calculated metrics below and in the Confusion Matrix section.\n"
     ]
    }
   ],
   "source": [
    "# This cell helps determine all of the True/False positives and negatives\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(testY)):\n",
    "    # if prediction and label for image is 1, True Positive\n",
    "    if (predictions[i] == 1 and testY[i] == 1):\n",
    "        TP += 1\n",
    "    # if prediction and label for image is 0, True Negative\n",
    "    elif(predictions[i] == 0 and testY[i] == 0):\n",
    "        TN += 1\n",
    "    # if prediction is Positive but label for image is Negative, False Positive\n",
    "    elif(predictions[i] == 1 and testY[i] == 0):\n",
    "        FP += 1\n",
    "    # if prediction is Positive but label for image is Negative, False Positive\n",
    "    elif(predictions[i] == 0 and testY[i] == 1):\n",
    "        FN += 1\n",
    "print(\"True Positives: \" + str(TP))\n",
    "print(\"True Negatives: \" + str(TN))\n",
    "print(\"False Positives: \" + str(FP))\n",
    "print(\"False Negatives: \" + str(FN))\n",
    "print()\n",
    "print(\"Observe these values in the calculated metrics below and in the Confusion Matrix section.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the values above to calculate our metrics. These will help us understand our **confusion matrix**. The **confusion matrix** can also help us calculate our metric values too.\n",
    "\n",
    "$$ Sensitivity = \\frac{(14)}{(14) + (1)} = \\frac{14}{15} $$\n",
    "\n",
    "\n",
    "$$ Specificity = \\frac{(15)}{(0) + (15)} = \\frac{15}{15} = 1 $$\n",
    "\n",
    "\n",
    "$$ PPV = \\frac{(14)}{(14) + (0)} = \\frac{14}{14} = 1 $$\n",
    "\n",
    "\n",
    "$$ NPV = \\frac{(15)}{(15) + (1)} = \\frac{15}{16} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge2\"></a>\n",
    "## CHALLENGE\n",
    "Given the following information, calculate the True/False Positives/Negatives, as well as the Sensitivity, Specificity, PPV, and NPV by filling in the **None** sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Run the cell after each challenge block to see if you got the right answers. Once you get each answer correct, you will see a congradulations message. </li>\n",
    "    <li> When entering values into a Fraction object, you may assume that Fractions will reduce. Thus, entering Fraction(25, 100) will be the same as entering Fraction(1, 4), and both answers are acceptable and are graded as the same value. For more information, see <a href=\"https://docs.python.org/3/library/fractions.html\" > fraction.Fraction(numerator=0, denominator=1) </a>\n",
    "    \n",
    "\n",
    "</ul>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challengeEx2\"></a>\n",
    "#### Example\n",
    "\n",
    "We are training our network to recognize a fracture in a bone from an x-ray image. Out of the 50 x-rays in the dataset, 35 of the x-rays show a fracture in a bone. The model was able to detect that 33 x-rays have a fracture in a bone from these 35 x-rays. Out of the remaining images from the dataset (ground truth is no fracture), all of the images were predicted that there was no fracture. *Assume a fracture in the x-ray to be Positive and no fracture to be Negative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Enter answers below\n",
    "TP = 33\n",
    "TN = 15\n",
    "FP = 0\n",
    "FN = 2\n",
    "Sensitivity = Fraction(33, 35)\n",
    "Specificity = Fraction(15, 15)\n",
    "PPV = Fraction(33, 33)\n",
    "NPV = Fraction(15, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 33 is correct!\n",
      "True Negatives: 15 is correct!\n",
      "False Positives: 0 is correct!\n",
      "False Negatives: 2 is correct!\n",
      "\n",
      "Sensitivity: 33/35 is correct!\n",
      "Specificity: 1 is correct!\n",
      "PPV: 1 is correct!\n",
      "NPV: 15/17 is correct!\n",
      "\n",
      "Congratulations on completing Example 2!\n"
     ]
    }
   ],
   "source": [
    "helper.example2(TP, TN, FP, FN, Sensitivity, Specificity, PPV, NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge2_1\"></a>\n",
    "**Challenge 1**:\n",
    "We are training our network to recognize a stroke from an MRI. We have a dataset of 250 MRI's. 175 of the MRI's show that the brain does not have a stroke. 30 of the 175 MRI's were classified as a stroke. Out of the remaining MRI's in the dataset (ground truth is a stroke), 20 of them were not classified as a stroke. *Assume an MRI's showing a stroke to be Positive and an MRI's not showing a stroke to be Negative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument should be a string or a Rational instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2b53333d12be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mSensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mSpecificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mPPV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/fractions.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, numerator, denominator, _normalize)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 raise TypeError(\"argument should be a string \"\n\u001b[0m\u001b[1;32m    162\u001b[0m                                 \"or a Rational instance\")\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument should be a string or a Rational instance"
     ]
    }
   ],
   "source": [
    "# Challenge 1\n",
    "# Enter answers below\n",
    "TP = None\n",
    "TN = None\n",
    "FP = None\n",
    "FN = None\n",
    "Sensitivity = Fraction(None, None)\n",
    "Specificity = Fraction(None, None)\n",
    "PPV = Fraction(None, None)\n",
    "NPV = Fraction(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "helper.challenge2_1(TP, TN, FP, FN, Sensitivity, Specificity, PPV, NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"challenge2_2\"></a>\n",
    "**Challenge 2**: We are training a network to recognize Type I and Type II Diabetes from a dataset of medical images. However, the dataset also contain images that are neither Type I or Type II Diabetes. Out of a database of 750 images, 100 of the images are neither Type I or Type II Diabetes. There are 400 Type I Diabetes images and the model correctly predicted 300 of them. 25 of the 400 images were classified as Type II Diabetes. The remaining 250 images are Type II Diabetes images, the model predicted that 40 of them were neither Type I or Type II Diabetes, and that 10 of the images were Type I Diabetes. *Assume Positives to be Type I Diabetes, and Negative to be Type II Diabetes images*.\n",
    "\n",
    "Note: You may ignore the *class* of neither Type I or Type II Diabetes images, but you must consider these images when calculating your metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Try not to think too much about \"Type I\" vs. \"Type II\" vs. \"neither\", but rather think about \"Type I\" vs. \"not Type I\" and \"Type II\" vs. \"not Type II\". The two \"not\" classes will be shared together. </li>\n",
    "    <li> Since we can ignore the class of neither Type I or Type II images, think about how these images represent the positives and negatives that we are focusing on. Are they True or False? Will they always be True or False? </li>\n",
    "    <li> There are 750 total images, but 100 of the images are neither Type I or Type II. Think about the definition of True Positives, True Negatives, False Positives, and False Negatives. Should the sum of all of these categories be 650 or 750? </li>\n",
    "    <li> Given that our data will fall under the Positive or Negative categories and that the class of neither Type I nor Type II images are Positive or Negative, how will this effect our True/False Positives/Negatives? </li>\n",
    "\n",
    "</ul>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n",
    "# Enter answers below\n",
    "TP = None\n",
    "TN = None\n",
    "FP = None\n",
    "FN = None\n",
    "Sensitivity = Fraction(None, None)\n",
    "Specificity = Fraction(None, None)\n",
    "PPV = Fraction(None, None)\n",
    "NPV = Fraction(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.challenge2_2(TP, TN, FP, FN, Sensitivity, Specificity, PPV, NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Conf-Matrix\"></a>\n",
    "## Confusion Matrix\n",
    "A Confusion Matrix is a metric that allows us to visualize our True/False Positives/Negatives. This metric will allow us to visualize the number of correctly and incorrectly predicted examples, which can help us calculate our sensitivity, specificity, PPV, and NPV.\n",
    "\n",
    "Observe the values of the confusion matrix below. Where are all of the True/False Positives/Negatives? \n",
    "\n",
    "How does each value relate to all of the metrics calculate above (before the challenge)? \n",
    "\n",
    "What do the colors represent in the matrix? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and print out the confusion matrix. \n",
    "\n",
    "# This confusion matrix is non-normalized, which shows the total number of \n",
    "# examples in the training set that fall into the 4 catagories\n",
    "\n",
    "mat = plot_confusion_matrix(classifier, testX, testY, \n",
    "                            display_labels=[\"Sick\", \"Healthy\"],\n",
    "                            cmap=plt.cm.Blues,\n",
    "                            normalize=None)\n",
    "mat.ax_.set_title(\"Confusion Matrix\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(mat.confusion_matrix)\n",
    "plt.grid(False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should recognize that the darker blue colors represents a higher quantity for that particular metric, while paler blue colors represent less of a quantity. We can also observe that since our model had a high accuracy (27 out of 30 classified correctly), the majority of our examples are in the top left and bottom right sections of the confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also represent the confusion matrix with a normalization metric. A **normalized confusion matrix** is a confusion matrix where all values are between 0 and 1. The purpose of the normalization is to see classifications of classes as a *percentage*, rather than just numbers. For instance, the group of True Positives in the nomalized confusion matrix is the *percentage* of Positive examples that are correctly classified as Positive. The False Positives is the *percentage* of Positive Examples that are classified as Negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and print out the confusion matrix. \n",
    "\n",
    "# This confusion matrix is normalized, which shows the total number of examples\n",
    "# in the training set as a percentage between 0 and 1\n",
    "\n",
    "# Sets the number of decimal points in the printed confusion matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "mat = plot_confusion_matrix(classifier, testX, testY, \n",
    "                            display_labels=[\"Sick\", \"Healthy\"],\n",
    "                            cmap=plt.cm.Blues,\n",
    "                            normalize='true')\n",
    "mat.ax_.set_title(\"Normalized Confusion Matrix\")\n",
    "print(\"Normalized Confusion Matrix\")\n",
    "print(mat.confusion_matrix)\n",
    "plt.grid(False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!\n",
    "\n",
    "You now know how to calculate metrics given a dataset. We can train our model to recognize patterns in our dataset and determine if our patient has COVID-19 or not. Metrics will help us determine the accuracy of our model to determine further patients. As a treatment to this disease, we can analyze the relationship between features and the status of the patient in order to understand the causes of COVID-19."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
